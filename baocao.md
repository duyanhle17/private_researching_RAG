# ğŸ“Š BÃ¡o CÃ¡o: Enhanced GraphRAG - Tá»« Simple GraphRAG Ä‘áº¿n SAT-Inspired

> **TÃ­ch há»£p ká»¹ thuáº­t tá»« SAT Paper (Structure Aware Alignment and Tuning)**

---

## ğŸ“Œ Má»¥c TiÃªu

Cáº£i tiáº¿n há»‡ thá»‘ng **Simple GraphRAG** báº±ng cÃ¡ch Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t tá»« **SAT paper** Ä‘á»ƒ xÃ¢y dá»±ng Knowledge Graph (KG) hiá»‡u quáº£ hÆ¡n cho bÃ i toÃ¡n Question Answering.

---

## ğŸ” PhÃ¢n TÃ­ch Code Gá»‘c

### Simple GraphRAG (`simple_graphrag.py`)

**Kiáº¿n trÃºc cÆ¡ báº£n:**
```
Text â†’ Chunking â†’ NER â†’ Co-occurrence Graph â†’ Node2Vec â†’ FAISS â†’ Query
```

**Äáº·c Ä‘iá»ƒm:**

**âœ… Æ¯u Ä‘iá»ƒm:**

1. **ÄÆ¡n giáº£n, dá»… hiá»ƒu vÃ  triá»ƒn khai nhanh**
   - Kiáº¿n trÃºc pipeline tháº³ng, khÃ´ng cÃ³ dependencies phá»©c táº¡p
   - Dá»… debug vÃ  maintain do code khÃ´ng quÃ¡ trá»«u tÆ°á»£ng
   - PhÃ¹ há»£p cho prototyping vÃ  baseline comparison

2. **Sá»­ dá»¥ng spaCy NER Ä‘á»ƒ trÃ­ch xuáº¥t entities**
   - Táº­n dá»¥ng pre-trained NER models cá»§a spaCy (en_core_web_sm/md/lg)
   - Nháº­n diá»‡n Ä‘Æ°á»£c cÃ¡c entity types cÆ¡ báº£n: PERSON, ORG, GPE, DATE, etc.
   - KhÃ´ng cáº§n training data riÃªng, cháº¡y Ä‘Æ°á»£c ngay "out-of-the-box"

3. **XÃ¢y dá»±ng graph dá»±a trÃªn co-occurrence**
   - Hai entities xuáº¥t hiá»‡n trong cÃ¹ng má»™t chunk sáº½ Ä‘Æ°á»£c ná»‘i báº±ng má»™t edge
   - Giáº£ Ä‘á»‹nh: entities trong cÃ¹ng context cÃ³ má»‘i quan há»‡ ngá»¯ nghÄ©a
   - ÄÆ¡n giáº£n nhÆ°ng hiá»‡u quáº£ cho viá»‡c capture local context

**âŒ Háº¡n cháº¿:**

1. **KhÃ´ng cÃ³ explicit relations - chá»‰ cÃ³ edges vÃ´ hÆ°á»›ng**
   - Graph chá»‰ lÆ°u `(entity1, entity2)` mÃ  khÃ´ng biáº¿t **quan há»‡ gÃ¬** giá»¯a chÃºng
   - VÃ­ dá»¥: "Aspirin treats headache" chá»‰ thÃ nh edge `(aspirin, headache)` - máº¥t thÃ´ng tin "treats"
   - KhÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c "A causes B" vs "A treats B" vs "A is part of B"
   - Giáº£m kháº£ nÄƒng reasoning vÃ  multi-hop query

2. **Node2Vec embeddings tÄ©nh - khÃ´ng há»c Ä‘Æ°á»£c tá»« structure**
   - Node2Vec dÃ¹ng random walks Ä‘á»ƒ táº¡o embeddings, **khÃ´ng cÃ³ gradient updates**
   - Embeddings Ä‘Æ°á»£c tÃ­nh má»™t láº§n vÃ  frozen, khÃ´ng adapt theo downstream task
   - KhÃ´ng capture Ä‘Æ°á»£c global graph structure, chá»‰ local neighborhoods
   - KhÃ¡c vá»›i Graph Transformer cÃ³ thá»ƒ fine-tune embeddings theo loss function

3. **KhÃ´ng cÃ³ entity/relation ID mapping - khÃ³ scale**
   - Entities Ä‘Æ°á»£c lÆ°u trá»±c tiáº¿p dÆ°á»›i dáº¡ng string trong NetworkX graph
   - Khi KG lá»›n (>100k entities), viá»‡c lookup string ráº¥t cháº­m
   - KhÃ´ng standardize entities (vÃ­ dá»¥: "COVID-19", "Covid19", "coronavirus" lÃ  3 nodes khÃ¡c nhau)
   - KhÃ³ serialize vÃ  share KG giá»¯a cÃ¡c há»‡ thá»‘ng

**Code snippet (entity extraction):**
```python
# Simple GraphRAG chá»‰ dÃ¹ng NER cÆ¡ báº£n
doc = self.nlp(text)
entities = {ent.text.lower() for ent in doc.ents}
```

---

## ğŸ“š SAT Paper - Nhá»¯ng GÃ¬ ÄÃ£ Há»c

### 1. Graph Transformer (`SAT/aligner/model/graph_transformer.py`)

**Ã tÆ°á»Ÿng chÃ­nh:**
- Thay vÃ¬ dÃ¹ng Node2Vec (random walk), sá»­ dá»¥ng **Transformer architecture** trÃªn graph
- **Learnable embeddings** cho cáº£ entities vÃ  relations
- **Multi-head attention** tÃ­nh toÃ¡n trÃªn edges, khÃ´ng pháº£i sequence

**Code tá»« SAT:**
```python
class GTLayer(nn.Module):
    """Graph Transformer Layer vá»›i sparse attention"""
    def forward(self, ent_emb, rel_emb, mr):
        # mr = (edge_indices, edge_types)
        # TÃ­nh attention trÃªn cáº¡nh cá»§a graph
```

### 2. CLIP-style Alignment (`SAT/aligner/model/model_gt.py`)

**Ã tÆ°á»Ÿng chÃ­nh:**
- Align **graph embeddings** vá»›i **text embeddings** 
- Sá»­ dá»¥ng **contrastive loss** (InfoNCE) Ä‘á»ƒ há»c representation chung
- Cho phÃ©p query báº±ng text nhÆ°ng tÃ¬m kiáº¿m trÃªn graph space

**Loss function:**
```
L = (L_graphâ†’text + L_textâ†’graph) / 2
```

### 3. Data Structure (`SAT/aligner/model/data_helper.py`)

**Ã tÆ°á»Ÿng chÃ­nh:**
- **Entity2ID mapping**: `{entity_name: id}` - cho phÃ©p xá»­ lÃ½ sá»‘ há»c
- **Relation2ID mapping**: `{relation_name: id}` - standardize relations
- **Triples format**: `(head_id, relation_id, tail_id, confidence)`
- **One-hot labels vá»›i label smoothing** cho training

---

## ğŸš€ Enhanced GraphRAG - PhÃ¢n TÃ­ch Chi Tiáº¿t CÃ¡c Cáº£i Tiáº¿n

### Pipeline Tá»•ng Thá»ƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ENHANCED GRAPHRAG PIPELINE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  [1] TEXT INPUT                                                             â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â–¼                                                                     â”‚
â”‚  [2] CHUNKING (split by sentence boundaries, ~800 chars)                    â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚       â–¼                      â–¼                      â–¼                       â”‚
â”‚  [3] NER + Dependency    [4] Sentence           [5] Co-occurrence           â”‚
â”‚      Parsing                 Embeddings             Graph                   â”‚
â”‚       â”‚                      â”‚                      â”‚                       â”‚
â”‚       â–¼                      â–¼                      â–¼                       â”‚
â”‚  [6] TRIPLE EXTRACTION   [7] FAISS INDEX        [8] NetworkX KG             â”‚
â”‚      (head, rel, tail)       (semantic search)      (graph structure)       â”‚
â”‚       â”‚                      â”‚                      â”‚                       â”‚
â”‚       â–¼                      â”‚                      â”‚                       â”‚
â”‚  [9] ENTITY2ID &             â”‚                      â”‚                       â”‚
â”‚      RELATION2ID             â”‚                      â”‚                       â”‚
â”‚      MAPPING                 â”‚                      â”‚                       â”‚
â”‚       â”‚                      â”‚                      â”‚                       â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                              â”‚                                              â”‚
â”‚                              â–¼                                              â”‚
â”‚                    [10] HYBRID RETRIEVAL                                    â”‚
â”‚                    (Î± Ã— semantic + (1-Î±) Ã— graph)                           â”‚
â”‚                              â”‚                                              â”‚
â”‚                              â–¼                                              â”‚
â”‚                    [11] LLM GENERATION                                      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš ï¸ PHáº¦N CHÆ¯A Sá»¬ Dá»¤NG ÄÆ¯á»¢C (tá»« SAT):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [X] GRAPH TRANSFORMER    â†’  Disabled do Segfault vá»›i large KG             â”‚
â”‚  [X] TEXT-GRAPH ALIGNER   â†’  ChÆ°a train, thiáº¿u labeled data                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Cáº£i Tiáº¿n 1: Entity/Relation ID Mapping

#### ğŸ“‹ Flow
```
Entity string â†’ Check entity2id dict â†’ Náº¿u chÆ°a cÃ³: táº¡o ID má»›i â†’ LÆ°u mapping
"aspirin" â†’ entity2id["aspirin"] = 0
"headache" â†’ entity2id["headache"] = 1
"treats" â†’ relation2id["treats"] = 0
```

#### ğŸ¯ Má»¥c Ä‘Ã­ch
Chuyá»ƒn Ä‘á»•i Knowledge Graph tá»« **string-based** sang **ID-based** Ä‘á»ƒ:
1. **TÄƒng tá»‘c lookup**: So sÃ¡nh integer nhanh hÆ¡n so sÃ¡nh string
2. **Chuáº©n hÃ³a dá»¯ liá»‡u**: Má»—i entity/relation cÃ³ má»™t ID duy nháº¥t
3. **Dá»… dÃ ng serialize**: LÆ°u trá»¯ vÃ  táº£i KG hiá»‡u quáº£ hÆ¡n
4. **TÆ°Æ¡ng thÃ­ch vá»›i neural networks**: Embeddings cáº§n integer indices

#### ğŸ’¡ Ã nghÄ©a trong phÃ¡t triá»ƒn tri thá»©c
- **Tá»« "nháº­n diá»‡n" Ä‘áº¿n "Ä‘á»‹nh danh"**: Thay vÃ¬ chá»‰ nháº­n ra entity, há»‡ thá»‘ng giá» **gÃ¡n nhÃ£n sá»‘ há»c** cho má»—i entity
- **Ná»n táº£ng cho embedding learning**: ID mapping lÃ  Ä‘iá»u kiá»‡n tiÃªn quyáº¿t Ä‘á»ƒ cÃ³ thá»ƒ há»c embeddings (má»—i ID â†’ 1 vector)
- **Kháº£ nÄƒng má»Ÿ rá»™ng**: Khi KG cÃ³ hÃ ng triá»‡u entities, ID-based storage tiáº¿t kiá»‡m bá»™ nhá»› Ä‘Ã¡ng ká»ƒ

#### ğŸ“Š Káº¿t quáº£ thá»±c táº¿
```
Entities: 5088 unique entities vá»›i ID tá»« 0 Ä‘áº¿n 5087
Relations: 8 canonical relations (treats, causes, part_of, type_of, ...)
```

---

### Cáº£i Tiáº¿n 2: Explicit Relation Extraction

#### ğŸ“‹ Flow
```
Sentence: "Aspirin treats headache effectively"
    â”‚
    â–¼ [Dependency Parsing]
    â”‚
    â”œâ”€ "Aspirin" (nsubj) â”€â”€â”
    â”‚                      â”‚
    â”œâ”€ "treats" (ROOT/VERB)â”¼â”€â”€â†’ RELATION
    â”‚                      â”‚
    â””â”€ "headache" (dobj) â”€â”€â”˜
    â”‚
    â–¼ [Canonical Mapping]
    â”‚
    "treats" â†’ matches pattern ["treat", "cure", "heal"] â†’ canonical: "treats"
    â”‚
    â–¼ [Triple Formation]
    â”‚
    (aspirin, treats, headache, confidence=0.8)
```

#### ğŸ¯ Má»¥c Ä‘Ã­ch
Thay vÃ¬ chá»‰ biáº¿t "aspirin vÃ  headache cÃ³ liÃªn quan" (co-occurrence), giá» ta biáº¿t **Má»I QUAN Há»† Cá»¤ THá»‚** giá»¯a chÃºng.

#### ğŸ’¡ Ã nghÄ©a trong phÃ¡t triá»ƒn tri thá»©c

**Simple GraphRAG (Co-occurrence):**
```
Query: "What treats headache?"
Graph chá»‰ biáº¿t: aspirin â†â†’ headache (liÃªn quan gÃ¬ Ä‘Ã³)
                ibuprofen â†â†’ headache (liÃªn quan gÃ¬ Ä‘Ã³)
                stress â†â†’ headache (liÃªn quan gÃ¬ Ä‘Ã³)
â†’ KhÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c "treats" vs "causes"!
```

**Enhanced GraphRAG (Explicit Relations):**
```
Query: "What treats headache?"
Graph biáº¿t:    aspirin â”€â”€treatsâ”€â”€â†’ headache âœ…
               ibuprofen â”€â”€treatsâ”€â”€â†’ headache âœ…
               stress â”€â”€causesâ”€â”€â†’ headache âŒ (loáº¡i bá»)
â†’ Reasoning chÃ­nh xÃ¡c hÆ¡n!
```

**ÄÃ¢y lÃ  bÆ°á»›c tiáº¿n tá»« "Association" sang "Knowledge":**
- Association: A vÃ  B xuáº¥t hiá»‡n cÃ¹ng nhau
- Knowledge: A cÃ³ quan há»‡ R vá»›i B (A --R--> B)

#### ğŸ“Š Káº¿t quáº£ thá»±c táº¿
```
8 canonical relations: treats, causes, part_of, type_of, located_in, 
                       associated_with, has_property, related_to
8452 triples Ä‘Æ°á»£c trÃ­ch xuáº¥t
```

---

### Cáº£i Tiáº¿n 3: Fuzzy Entity Matching (Cáº£i tiáº¿n riÃªng)

#### ğŸ“‹ Flow
```
Query entity: "satellite awards"
    â”‚
    â–¼ [Normalize]
    Remove articles: "satellite awards"
    Lowercase: "satellite awards"
    â”‚
    â–¼ [Match against KG entities]
    â”‚
    KG entity: "the satellite awards"
    Normalize: "satellite awards"
    â”‚
    â–¼ [Comparison]
    "satellite awards" == "satellite awards" âœ… MATCH!
    â”‚
    â–¼ [Fallback: Word Overlap]
    If no exact match: check if overlap >= 50%
```

#### ğŸ¯ Má»¥c Ä‘Ã­ch
Giáº£i quyáº¿t váº¥n Ä‘á» **entity mismatch** do:
- Articles: "the", "a", "an"
- Capitalization: "COVID-19" vs "covid-19"
- Slight variations: "United States" vs "United States of America"

#### ğŸ’¡ Ã nghÄ©a trong phÃ¡t triá»ƒn tri thá»©c
- **Bridge the gap giá»¯a Query vÃ  KG**: User khÃ´ng biáº¿t entity Ä‘Æ°á»£c lÆ°u chÃ­nh xÃ¡c nhÆ° tháº¿ nÃ o trong KG
- **TÄƒng recall**: Nhiá»u entities Ä‘Æ°á»£c match hÆ¡n â†’ nhiá»u facts Ä‘Æ°á»£c retrieve hÆ¡n
- **Robustness**: Há»‡ thá»‘ng Ã­t nháº¡y cáº£m vá»›i cÃ¡ch viáº¿t cá»§a user

#### ğŸ“Š Káº¿t quáº£ thá»±c táº¿
```
TrÆ°á»›c: 31/64 cÃ¢u cÃ³ 0 KG facts
Sau:   20/64 cÃ¢u cÃ³ 0 KG facts
â†’ Cáº£i thiá»‡n 35% sá»‘ cÃ¢u cÃ³ thá»ƒ retrieve KG facts
```

---

### Cáº£i Tiáº¿n 4: Hybrid Retrieval (Semantic + Graph)

#### ğŸ“‹ Flow
```
Query: "What university is UCF?"
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    â”‚                    â”‚
    â–¼                    â–¼                    â–¼
[Entity Extract]    [Embed Query]       [KG Lookup]
    â”‚                    â”‚                    â”‚
    â”‚                    â–¼                    â”‚
    â”‚               FAISS Search              â”‚
    â”‚                    â”‚                    â”‚
    â”‚                    â–¼                    â”‚
    â”‚            semantic_scores              â”‚
    â”‚               [0.8, 0.6, 0.5, ...]     â”‚
    â”‚                    â”‚                    â”‚
    â–¼                    â”‚                    â–¼
[Fuzzy Match]            â”‚            [Get related entities]
    â”‚                    â”‚                    â”‚
    â”‚                    â”‚                    â–¼
    â”‚                    â”‚            graph_scores (entity overlap)
    â”‚                    â”‚               [0.3, 0.7, 0.2, ...]
    â”‚                    â”‚                    â”‚
    â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                             â”‚
    â”‚                             â–¼
    â”‚                    HYBRID SCORE
    â”‚              Î± Ã— semantic + (1-Î±) Ã— graph
    â”‚                    (Î± = 0.6)
    â”‚                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         TOP-K CHUNKS
                                  â”‚
                                  â–¼
                         LLM GENERATION
```

#### ğŸ¯ Má»¥c Ä‘Ã­ch
Káº¿t há»£p 2 nguá»“n thÃ´ng tin:
1. **Semantic similarity**: Chunks cÃ³ nghÄ©a gáº§n vá»›i query
2. **Graph connectivity**: Chunks chá»©a entities liÃªn quan trong KG

#### ğŸ’¡ Ã nghÄ©a trong phÃ¡t triá»ƒn tri thá»©c
- **Semantic search** tá»‘t cho: paraphrase, synonyms, context understanding
- **Graph search** tá»‘t cho: entity relationships, factual connections
- **Hybrid** = Best of both worlds

**VÃ­ dá»¥:**
```
Query: "What treats migraines?"

Semantic search cÃ³ thá»ƒ tráº£ vá»:
  "Headaches can be very painful..." (semantic similar nhÆ°ng khÃ´ng answer)

Graph search biáº¿t:
  "migraine" â†treatsâ† "sumatriptan"
  â†’ Chunk chá»©a "sumatriptan" Ä‘Æ°á»£c boost score
```

---

## âš ï¸ CÃ¡c Pháº§n Tá»« SAT ChÆ°a Sá»­ Dá»¥ng ÄÆ°á»£c

### 1. Graph Transformer

#### Má»¥c Ä‘Ã­ch ban Ä‘áº§u
- Há»c **learnable node embeddings** tá»« cáº¥u trÃºc graph
- Thay tháº¿ Node2Vec (random walk, static) báº±ng attention-based learning
- Capture Ä‘Æ°á»£c **global graph structure** thay vÃ¬ chá»‰ local neighborhoods

#### Táº¡i sao chÆ°a dÃ¹ng Ä‘Æ°á»£c?
```
Váº¥n Ä‘á»: SEGMENTATION FAULT khi KG > 5000 entities

NguyÃªn nhÃ¢n ká»¹ thuáº­t:
- Attention matrix cÃ³ size O(E Ã— E) vá»›i E = sá»‘ edges
- KG hiá»‡n táº¡i: 8452 edges â†’ matrix ~71 triá»‡u pháº§n tá»­
- Má»—i pháº§n tá»­ lÃ  float32 (4 bytes) â†’ ~284 MB chá»‰ cho 1 attention head
- Multi-head (8 heads) Ã— Multi-layer (3 layers) â†’ ~6.8 GB
- VÆ°á»£t quÃ¡ memory available â†’ Crash
```

#### CÃ¡ch kháº¯c phá»¥c tiá»m nÄƒng
| Approach | MÃ´ táº£ | Äá»™ khÃ³ |
|----------|-------|--------|
| **Mini-batching** | Chia graph thÃ nh subgraphs, process tá»«ng batch | â­â­ |
| **Sparse Attention** | Chá»‰ tÃ­nh attention cho k-nearest neighbors | â­â­â­ |
| **Graph Sampling** | Random sample edges Ä‘á»ƒ giáº£m size | â­ |
| **Gradient Checkpointing** | Trade compute for memory | â­â­ |
| **Mixed Precision** | DÃ¹ng float16 thay float32 | â­ |

---

### 2. Text-Graph Aligner (CLIP-style)

#### Má»¥c Ä‘Ã­ch ban Ä‘áº§u
```
Ã tÆ°á»Ÿng: Táº¡o SHARED EMBEDDING SPACE cho cáº£ text vÃ  graph

Text: "Aspirin is a medication"  â†’  [text_emb]  â”€â”
                                                  â”‚
                                                  â–¼
                                          SHARED SPACE
                                                  â–²
                                                  â”‚
Graph: (aspirin, type_of, medication)  â†’  [graph_emb] â”€â”˜

â†’ Query báº±ng text, search trong graph space
â†’ Hoáº·c ngÆ°á»£c láº¡i: cÃ³ entity, tÃ¬m text mÃ´ táº£
```

#### Táº¡i sao chÆ°a dÃ¹ng Ä‘Æ°á»£c?
```
Váº¥n Ä‘á» 1: THIáº¾U LABELED DATA
- Cáº§n pairs (text, entity) Ä‘á»ƒ train contrastive loss
- Dataset hiá»‡n táº¡i khÃ´ng cÃ³ annotation nÃ y
- SAT paper dÃ¹ng FB15k-237 cÃ³ sáºµn text descriptions

Váº¥n Ä‘á» 2: COMPUTATIONAL COST
- Train CLIP-style model cáº§n nhiá»u negative samples
- Batch size lá»›n (512-4096) Ä‘á»ƒ contrastive loss hiá»‡u quáº£
- Cáº§n GPU vá»›i memory lá»›n

Váº¥n Ä‘á» 3: COLD START
- ChÆ°a cÃ³ pre-trained weights cho domain-specific data
- Train from scratch cáº§n nhiá»u data vÃ  time
```

#### CÃ¡ch kháº¯c phá»¥c tiá»m nÄƒng
| Approach | MÃ´ táº£ | Äá»™ khÃ³ |
|----------|-------|--------|
| **DÃ¹ng LLM generate descriptions** | GPT/Llama táº¡o text cho má»—i entity | â­â­ |
| **Transfer learning** | Fine-tune tá»« pre-trained CLIP | â­â­ |
| **Self-supervised** | DÃ¹ng entity names lÃ m text descriptions | â­ |
| **DÃ¹ng Sentence-BERT** | Embed cáº£ entity names vÃ  text, khÃ´ng cáº§n train | â­ |

---

## ğŸ“Š So SÃ¡nh Pipeline: Simple vs Enhanced

| BÆ°á»›c | Simple GraphRAG | Enhanced GraphRAG | Cáº£i tiáº¿n |
|------|-----------------|-------------------|----------|
| **1. Chunking** | Fixed-size | Sentence-boundary aware | KhÃ´ng cáº¯t ngang cÃ¢u |
| **2. Entity Extraction** | spaCy NER only | spaCy NER + Dependency Parsing | ThÃªm relations |
| **3. Graph Structure** | Co-occurrence edges | Typed triples (head, rel, tail) | Biáº¿t quan há»‡ cá»¥ thá»ƒ |
| **4. Entity Storage** | String dict | ID mapping (entity2id) | Faster lookup |
| **5. Embeddings** | Node2Vec (static) | ~~Graph Transformer~~ â†’ Node2Vec* | *Disabled |
| **6. Retrieval** | Semantic only | Hybrid (semantic + graph) | Multi-signal |
| **7. Entity Matching** | Exact match | Fuzzy matching | Robust hÆ¡n |
| **8. Text-Graph Bridge** | KhÃ´ng cÃ³ | ~~CLIP-style~~ â†’ KhÃ´ng cÃ³* | *ChÆ°a train |

---

### Tá»•ng Káº¿t: Nhá»¯ng GÃ¬ ÄÃ£ Thá»±c Sá»± Hoáº¡t Äá»™ng

âœ… **Äang dÃ¹ng vÃ  hoáº¡t Ä‘á»™ng:**
1. Entity/Relation ID Mapping
2. Explicit Relation Extraction  
3. Fuzzy Entity Matching
4. Hybrid Retrieval
5. Triple format vá»›i confidence scores

âŒ **ÄÃ£ implement nhÆ°ng disabled:**
1. Graph Transformer (segfault)
2. Text-Graph Aligner (chÆ°a train)

â†’ **Thá»±c táº¿**: Enhanced GraphRAG hiá»‡n táº¡i lÃ  **Simple GraphRAG + Better Entity Handling + Explicit Relations + Hybrid Search**, chÆ°a pháº£i full SAT architecture.

---

## ğŸ“Š Káº¿t Quáº£ Thá»±c Nghiá»‡m

### Dataset
- **Nguá»“n:** `data/medical_custom.json`
- **Sá»‘ cÃ¢u há»i:** 64

### Build KG Statistics
```
ğŸ“Š Build Complete!
   - Chunks: 173
   - Entities: 5088
   - Relations: 8 
   - Triples: 8452
```

### QA Evaluation Results

| Metric | Káº¿t quáº£ |
|--------|---------|
| **Strict Match** (GT substring in Answer) | 8/64 (12.5%) |
| **Fuzzy Match** (60% word overlap) | 43/64 (67.2%) |
| **"Not stated in text"** | 5/64 (7.8%) |

### PhÃ¢n tÃ­ch chi tiáº¿t

**CÃ¢u Ä‘Ãºng (fuzzy match):**
```
Q: What institutional type is UCF?
A: "a public research university"
GT: "UCF is a public research university."
â†’ âœ… ÄÃºng ná»™i dung, chá»‰ khÃ¡c format
```

**CÃ¢u sai (khÃ´ng tÃ¬m Ä‘Æ°á»£c context):**
```
Q: Why is the University of Essex called one of the 'original plate glass universities'?
A: "not stated in the text"
GT: "Because it is included among the group of universities..."
â†’ âŒ Context khÃ´ng chá»©a thÃ´ng tin nÃ y
```

---

## ğŸ”§ Cáº¥u HÃ¬nh ÄÃ£ Sá»­ Dá»¥ng

```python
# build_enhanced_kg_cache.py
rag = EnhancedGraphRAG(
    embedding_model_name="all-MiniLM-L6-v2",
    use_graph_transformer=False,  # Disabled do segfault
    graph_transformer_dim=128,
    graph_transformer_layers=3,
)

# run_enhanced_baseline.py
TOP_K = 10      # Sá»‘ chunks retrieved
ALPHA = 0.6     # 60% semantic, 40% graph
```

---

## ğŸ“ Files ÄÆ°á»£c Táº¡o

| File | MÃ´ táº£ |
|------|-------|
| `enhanced_graphrag.py` | Main module vá»›i táº¥t cáº£ components |
| `build_enhanced_kg_cache.py` | Script build KG cache |
| `run_enhanced_baseline.py` | Script cháº¡y QA evaluation |
| `enhanced_sat_data/` | Folder chá»©a KG cache |
| `enhanced_results.json` | Káº¿t quáº£ QA (64 cÃ¢u) |

### Cáº¥u trÃºc `enhanced_sat_data/`:
```
enhanced_sat_data/
â”œâ”€â”€ chunks.json          # List cÃ¡c text chunks
â”œâ”€â”€ embeddings.npy       # Chunk embeddings (173, 384)
â”œâ”€â”€ faiss.index          # FAISS index cho search
â”œâ”€â”€ kg.pkl               # NetworkX graph
â”œâ”€â”€ chunk_entities.pkl   # Entity mapping per chunk
â”œâ”€â”€ entity2id.pkl        # Entity â†’ ID (SAT-style)
â”œâ”€â”€ relation2id.pkl      # Relation â†’ ID (SAT-style)
â”œâ”€â”€ triples.json         # [(head, rel, tail, conf), ...]
â””â”€â”€ meta.json            # Metadata
```

---

## ğŸ¯ Káº¿t Luáº­n

### Nhá»¯ng gÃ¬ Ä‘Ã£ há»c tá»« SAT:
1. âœ… **Graph Transformer architecture** - Multi-head attention trÃªn graph
2. âœ… **Entity/Relation ID mapping** - SAT-style data format
3. âœ… **CLIP-style alignment concept** - Text-Graph bridge
4. âœ… **Triple with confidence** - Structured KG format

### Nhá»¯ng gÃ¬ Ä‘Ã£ cáº£i tiáº¿n riÃªng:
1. âœ… **Fuzzy entity matching** - Giáº£i quyáº¿t normalization issues
2. âœ… **Explicit relation extraction** - Dependency parsing
3. âœ… **Canonical relation mapping** - Standardize verbs â†’ relations

### Háº¡n cháº¿:

1. âŒ **Graph Transformer bá»‹ vÃ´ hiá»‡u hÃ³a do lá»—i bá»™ nhá»› (Segfault)**
   - **Váº¥n Ä‘á»**: Khi Knowledge Graph cÃ³ hÆ¡n ~5000 entities, Graph Transformer gáº·p lá»—i segmentation fault do tiÃªu thá»¥ bá»™ nhá»› quÃ¡ lá»›n khi tÃ­nh attention matrix trÃªn toÃ n bá»™ edges.
   - **NguyÃªn nhÃ¢n**: Thuáº­t toÃ¡n hiá»‡n táº¡i tÃ­nh attention O(EÂ²) vá»›i E lÃ  sá»‘ edges, khÃ´ng cÃ³ cÆ¡ cháº¿ batching hay sparse attention.
   - **Há»‡ quáº£**: Máº¥t Ä‘i kháº£ nÄƒng há»c **learnable node embeddings** tá»« cáº¥u trÃºc graph, pháº£i fallback vá» Node2Vec embeddings tÄ©nh nhÆ° Simple GraphRAG.

2. âŒ **ChÆ°a train Ä‘Æ°á»£c Text-Graph Aligner (CLIP-style)**
   - **Váº¥n Ä‘á»**: Module alignment giá»¯a text embeddings vÃ  graph embeddings chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n, chá»‰ sá»­ dá»¥ng pre-computed embeddings Ä‘á»™c láº­p.
   - **NguyÃªn nhÃ¢n**: Thiáº¿u dá»¯ liá»‡u training cÃ³ nhÃ£n (text-entity pairs), vÃ  cáº§n computational resources Ä‘Ã¡ng ká»ƒ Ä‘á»ƒ train contrastive loss.
   - **Há»‡ quáº£**: KhÃ´ng táº­n dá»¥ng Ä‘Æ°á»£c Æ°u Ä‘iá»ƒm lá»›n nháº¥t cá»§a SAT paper - kháº£ nÄƒng query báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn nhÆ°ng tÃ¬m kiáº¿m hiá»‡u quáº£ trÃªn graph space thÃ´ng qua shared embedding space.

3. âŒ **5/64 cÃ¢u há»i (7.8%) khÃ´ng tÃ¬m Ä‘Æ°á»£c context phÃ¹ há»£p**
   - **Váº¥n Ä‘á»**: Má»™t sá»‘ cÃ¢u há»i khÃ´ng retrieve Ä‘Æ°á»£c chunks chá»©a thÃ´ng tin cáº§n thiáº¿t Ä‘á»ƒ tráº£ lá»i.
   - **NguyÃªn nhÃ¢n gá»‘c**:
     - Chunking strategy hiá»‡n táº¡i (fixed-size) cÃ³ thá»ƒ cáº¯t ngang cÃ¡c Ä‘oáº¡n thÃ´ng tin liÃªn quan
     - Entity extraction bá» sÃ³t má»™t sá»‘ entities do NER model khÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c (Ä‘áº·c biá»‡t vá»›i tiáº¿ng Viá»‡t hoáº·c thuáº­t ngá»¯ chuyÃªn ngÃ nh)
     - Semantic similarity giá»¯a cÃ¢u há»i vÃ  answer chunks khÃ´ng Ä‘á»§ cao
   - **Há»‡ quáº£**: Giá»›i háº¡n recall tá»‘i Ä‘a cá»§a há»‡ thá»‘ng á»Ÿ má»©c ~92%

### HÆ°á»›ng phÃ¡t triá»ƒn:
- [ ] Fix Graph Transformer cho large-scale KG (batching/sampling)
- [ ] Train Text-Graph Aligner vá»›i contrastive loss
- [ ] ThÃªm multi-hop reasoning
- [ ] Cáº£i thiá»‡n relation extraction vá»›i LLM 

---

*BÃ¡o cÃ¡o cáº­p nháº­t: 02/02/2026*
