# ğŸ“Š BÃ¡o CÃ¡o: Enhanced GraphRAG - Tá»« Simple GraphRAG Ä‘áº¿n SAT-Inspired

> **TÃ­ch há»£p ká»¹ thuáº­t tá»« SAT Paper (Structure Aware Alignment and Tuning)**

---

## ğŸ“Œ Má»¥c TiÃªu

Cáº£i tiáº¿n há»‡ thá»‘ng **Simple GraphRAG** báº±ng cÃ¡ch Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t tá»« **SAT paper** Ä‘á»ƒ xÃ¢y dá»±ng Knowledge Graph (KG) hiá»‡u quáº£ hÆ¡n cho bÃ i toÃ¡n Question Answering.

---

## ğŸ” PhÃ¢n TÃ­ch Code Gá»‘c

### Simple GraphRAG (`simple_graphrag.py`)

**Kiáº¿n trÃºc cÆ¡ báº£n:**
```
Text â†’ Chunking â†’ NER â†’ Co-occurrence Graph â†’ Node2Vec â†’ FAISS â†’ Query
```

**Äáº·c Ä‘iá»ƒm:**

**âœ… Æ¯u Ä‘iá»ƒm:**

1. **ÄÆ¡n giáº£n, dá»… hiá»ƒu vÃ  triá»ƒn khai nhanh**
   - Kiáº¿n trÃºc pipeline tháº³ng, khÃ´ng cÃ³ dependencies phá»©c táº¡p
   - Dá»… debug vÃ  maintain do code khÃ´ng quÃ¡ trá»«u tÆ°á»£ng
   - PhÃ¹ há»£p cho prototyping vÃ  baseline comparison

2. **Sá»­ dá»¥ng spaCy NER Ä‘á»ƒ trÃ­ch xuáº¥t entities**
   - Táº­n dá»¥ng pre-trained NER models cá»§a spaCy (en_core_web_sm/md/lg)
   - Nháº­n diá»‡n Ä‘Æ°á»£c cÃ¡c entity types cÆ¡ báº£n: PERSON, ORG, GPE, DATE, etc.
   - KhÃ´ng cáº§n training data riÃªng, cháº¡y Ä‘Æ°á»£c ngay "out-of-the-box"

3. **XÃ¢y dá»±ng graph dá»±a trÃªn co-occurrence**
   - Hai entities xuáº¥t hiá»‡n trong cÃ¹ng má»™t chunk sáº½ Ä‘Æ°á»£c ná»‘i báº±ng má»™t edge
   - Giáº£ Ä‘á»‹nh: entities trong cÃ¹ng context cÃ³ má»‘i quan há»‡ ngá»¯ nghÄ©a
   - ÄÆ¡n giáº£n nhÆ°ng hiá»‡u quáº£ cho viá»‡c capture local context

**âŒ Háº¡n cháº¿:**

1. **KhÃ´ng cÃ³ explicit relations - chá»‰ cÃ³ edges vÃ´ hÆ°á»›ng**
   - Graph chá»‰ lÆ°u `(entity1, entity2)` mÃ  khÃ´ng biáº¿t **quan há»‡ gÃ¬** giá»¯a chÃºng
   - VÃ­ dá»¥: "Aspirin treats headache" chá»‰ thÃ nh edge `(aspirin, headache)` - máº¥t thÃ´ng tin "treats"
   - KhÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c "A causes B" vs "A treats B" vs "A is part of B"
   - Giáº£m kháº£ nÄƒng reasoning vÃ  multi-hop query

2. **Node2Vec embeddings tÄ©nh - khÃ´ng há»c Ä‘Æ°á»£c tá»« structure**
   - Node2Vec dÃ¹ng random walks Ä‘á»ƒ táº¡o embeddings, **khÃ´ng cÃ³ gradient updates**
   - Embeddings Ä‘Æ°á»£c tÃ­nh má»™t láº§n vÃ  frozen, khÃ´ng adapt theo downstream task
   - KhÃ´ng capture Ä‘Æ°á»£c global graph structure, chá»‰ local neighborhoods
   - KhÃ¡c vá»›i Graph Transformer cÃ³ thá»ƒ fine-tune embeddings theo loss function

3. **KhÃ´ng cÃ³ entity/relation ID mapping - khÃ³ scale**
   - Entities Ä‘Æ°á»£c lÆ°u trá»±c tiáº¿p dÆ°á»›i dáº¡ng string trong NetworkX graph
   - Khi KG lá»›n (>100k entities), viá»‡c lookup string ráº¥t cháº­m
   - KhÃ´ng standardize entities (vÃ­ dá»¥: "COVID-19", "Covid19", "coronavirus" lÃ  3 nodes khÃ¡c nhau)
   - KhÃ³ serialize vÃ  share KG giá»¯a cÃ¡c há»‡ thá»‘ng

**Code snippet (entity extraction):**
```python
# Simple GraphRAG chá»‰ dÃ¹ng NER cÆ¡ báº£n
doc = self.nlp(text)
entities = {ent.text.lower() for ent in doc.ents}
```

---

## ğŸ“š SAT Paper - Nhá»¯ng GÃ¬ ÄÃ£ Há»c

### 1. Graph Transformer (`SAT/aligner/model/graph_transformer.py`)

**Ã tÆ°á»Ÿng chÃ­nh:**
- Thay vÃ¬ dÃ¹ng Node2Vec (random walk), sá»­ dá»¥ng **Transformer architecture** trÃªn graph
- **Learnable embeddings** cho cáº£ entities vÃ  relations
- **Multi-head attention** tÃ­nh toÃ¡n trÃªn edges, khÃ´ng pháº£i sequence

**Code tá»« SAT:**
```python
class GTLayer(nn.Module):
    """Graph Transformer Layer vá»›i sparse attention"""
    def forward(self, ent_emb, rel_emb, mr):
        # mr = (edge_indices, edge_types)
        # TÃ­nh attention trÃªn cáº¡nh cá»§a graph
```

### 2. CLIP-style Alignment (`SAT/aligner/model/model_gt.py`)

**Ã tÆ°á»Ÿng chÃ­nh:**
- Align **graph embeddings** vá»›i **text embeddings** 
- Sá»­ dá»¥ng **contrastive loss** (InfoNCE) Ä‘á»ƒ há»c representation chung
- Cho phÃ©p query báº±ng text nhÆ°ng tÃ¬m kiáº¿m trÃªn graph space

**Loss function:**
```
L = (L_graphâ†’text + L_textâ†’graph) / 2
```

### 3. Data Structure (`SAT/aligner/model/data_helper.py`)

**Ã tÆ°á»Ÿng chÃ­nh:**
- **Entity2ID mapping**: `{entity_name: id}` - cho phÃ©p xá»­ lÃ½ sá»‘ há»c
- **Relation2ID mapping**: `{relation_name: id}` - standardize relations
- **Triples format**: `(head_id, relation_id, tail_id, confidence)`
- **One-hot labels vá»›i label smoothing** cho training

---

## ğŸš€ Enhanced GraphRAG - PhÃ¢n TÃ­ch Chi Tiáº¿t CÃ¡c Cáº£i Tiáº¿n

### Pipeline Tá»•ng Thá»ƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ENHANCED GRAPHRAG PIPELINE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  [1] TEXT INPUT                                                             â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â–¼                                                                     â”‚
â”‚  [2] CHUNKING (split by sentence boundaries, ~800 chars)                    â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚       â–¼                      â–¼                      â–¼                       â”‚
â”‚  [3] NER + Dependency    [4] Sentence           [5] Co-occurrence           â”‚
â”‚      Parsing                 Embeddings             Graph                   â”‚
â”‚       â”‚                      â”‚                      â”‚                       â”‚
â”‚       â–¼                      â–¼                      â–¼                       â”‚
â”‚  [6] TRIPLE EXTRACTION   [7] FAISS INDEX        [8] NetworkX KG             â”‚
â”‚      (head, rel, tail)       (semantic search)      (graph structure)       â”‚
â”‚       â”‚                      â”‚                      â”‚                       â”‚
â”‚       â–¼                      â”‚                      â”‚                       â”‚
â”‚  [9] ENTITY2ID &             â”‚                      â”‚                       â”‚
â”‚      RELATION2ID             â”‚                      â”‚                       â”‚
â”‚      MAPPING                 â”‚                      â”‚                       â”‚
â”‚       â”‚                      â”‚                      â”‚                       â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                              â”‚                                              â”‚
â”‚                              â–¼                                              â”‚
â”‚                    [10] HYBRID RETRIEVAL                                    â”‚
â”‚                    (Î± Ã— semantic + (1-Î±) Ã— graph)                           â”‚
â”‚                              â”‚                                              â”‚
â”‚                              â–¼                                              â”‚
â”‚                    [11] LLM GENERATION                                      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš ï¸ PHáº¦N CHÆ¯A Sá»¬ Dá»¤NG ÄÆ¯á»¢C (tá»« SAT):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [X] GRAPH TRANSFORMER    â†’  Disabled do Segfault vá»›i large KG             â”‚
â”‚  [X] TEXT-GRAPH ALIGNER   â†’  ChÆ°a train, thiáº¿u labeled data                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Cáº£i Tiáº¿n 1: Entity/Relation ID Mapping

#### ğŸ“‹ Flow
```
Entity string â†’ Check entity2id dict â†’ Náº¿u chÆ°a cÃ³: táº¡o ID má»›i â†’ LÆ°u mapping
"aspirin" â†’ entity2id["aspirin"] = 0
"headache" â†’ entity2id["headache"] = 1
"treats" â†’ relation2id["treats"] = 0
```

#### ğŸ¯ Má»¥c Ä‘Ã­ch
Chuyá»ƒn Ä‘á»•i Knowledge Graph tá»« **string-based** sang **ID-based** Ä‘á»ƒ:
1. **TÄƒng tá»‘c lookup**: So sÃ¡nh integer nhanh hÆ¡n so sÃ¡nh string
2. **Chuáº©n hÃ³a dá»¯ liá»‡u**: Má»—i entity/relation cÃ³ má»™t ID duy nháº¥t
3. **Dá»… dÃ ng serialize**: LÆ°u trá»¯ vÃ  táº£i KG hiá»‡u quáº£ hÆ¡n
4. **TÆ°Æ¡ng thÃ­ch vá»›i neural networks**: Embeddings cáº§n integer indices

#### ğŸ’¡ Ã nghÄ©a trong phÃ¡t triá»ƒn tri thá»©c
- **Tá»« "nháº­n diá»‡n" Ä‘áº¿n "Ä‘á»‹nh danh"**: Thay vÃ¬ chá»‰ nháº­n ra entity, há»‡ thá»‘ng giá» **gÃ¡n nhÃ£n sá»‘ há»c** cho má»—i entity
- **Ná»n táº£ng cho embedding learning**: ID mapping lÃ  Ä‘iá»u kiá»‡n tiÃªn quyáº¿t Ä‘á»ƒ cÃ³ thá»ƒ há»c embeddings (má»—i ID â†’ 1 vector)
- **Kháº£ nÄƒng má»Ÿ rá»™ng**: Khi KG cÃ³ hÃ ng triá»‡u entities, ID-based storage tiáº¿t kiá»‡m bá»™ nhá»› Ä‘Ã¡ng ká»ƒ

#### ğŸ“Š Káº¿t quáº£ thá»±c táº¿
```
Entities: 5088 unique entities vá»›i ID tá»« 0 Ä‘áº¿n 5087
Relations: 8 canonical relations (treats, causes, part_of, type_of, ...)
```

---

### Cáº£i Tiáº¿n 2: Explicit Relation Extraction

#### ğŸ“‹ Flow
```
Sentence: "Aspirin treats headache effectively"
    â”‚
    â–¼ [Dependency Parsing]
    â”‚
    â”œâ”€ "Aspirin" (nsubj) â”€â”€â”
    â”‚                      â”‚
    â”œâ”€ "treats" (ROOT/VERB)â”¼â”€â”€â†’ RELATION
    â”‚                      â”‚
    â””â”€ "headache" (dobj) â”€â”€â”˜
    â”‚
    â–¼ [Canonical Mapping]
    â”‚
    "treats" â†’ matches pattern ["treat", "cure", "heal"] â†’ canonical: "treats"
    â”‚
    â–¼ [Triple Formation]
    â”‚
    (aspirin, treats, headache, confidence=0.8)
```

#### ğŸ¯ Má»¥c Ä‘Ã­ch
Thay vÃ¬ chá»‰ biáº¿t "aspirin vÃ  headache cÃ³ liÃªn quan" (co-occurrence), giá» ta biáº¿t **Má»I QUAN Há»† Cá»¤ THá»‚** giá»¯a chÃºng.

#### ğŸ’¡ Ã nghÄ©a trong phÃ¡t triá»ƒn tri thá»©c

**Simple GraphRAG (Co-occurrence):**
```
Query: "What treats headache?"
Graph chá»‰ biáº¿t: aspirin â†â†’ headache (liÃªn quan gÃ¬ Ä‘Ã³)
                ibuprofen â†â†’ headache (liÃªn quan gÃ¬ Ä‘Ã³)
                stress â†â†’ headache (liÃªn quan gÃ¬ Ä‘Ã³)
â†’ KhÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c "treats" vs "causes"!
```

**Enhanced GraphRAG (Explicit Relations):**
```
Query: "What treats headache?"
Graph biáº¿t:    aspirin â”€â”€treatsâ”€â”€â†’ headache âœ…
               ibuprofen â”€â”€treatsâ”€â”€â†’ headache âœ…
               stress â”€â”€causesâ”€â”€â†’ headache âŒ (loáº¡i bá»)
â†’ Reasoning chÃ­nh xÃ¡c hÆ¡n!
```

**ÄÃ¢y lÃ  bÆ°á»›c tiáº¿n tá»« "Association" sang "Knowledge":**
- Association: A vÃ  B xuáº¥t hiá»‡n cÃ¹ng nhau
- Knowledge: A cÃ³ quan há»‡ R vá»›i B (A --R--> B)

#### ğŸ“Š Káº¿t quáº£ thá»±c táº¿
```
8 canonical relations: treats, causes, part_of, type_of, located_in, 
                       associated_with, has_property, related_to
8452 triples Ä‘Æ°á»£c trÃ­ch xuáº¥t
```

---

### Cáº£i Tiáº¿n 3: Fuzzy Entity Matching (Cáº£i tiáº¿n riÃªng)

#### ğŸ“‹ Flow
```
Query entity: "satellite awards"
    â”‚
    â–¼ [Normalize]
    Remove articles: "satellite awards"
    Lowercase: "satellite awards"
    â”‚
    â–¼ [Match against KG entities]
    â”‚
    KG entity: "the satellite awards"
    Normalize: "satellite awards"
    â”‚
    â–¼ [Comparison]
    "satellite awards" == "satellite awards" âœ… MATCH!
    â”‚
    â–¼ [Fallback: Word Overlap]
    If no exact match: check if overlap >= 50%
```

#### ğŸ¯ Má»¥c Ä‘Ã­ch
Giáº£i quyáº¿t váº¥n Ä‘á» **entity mismatch** do:
- Articles: "the", "a", "an"
- Capitalization: "COVID-19" vs "covid-19"
- Slight variations: "United States" vs "United States of America"

#### ğŸ’¡ Ã nghÄ©a trong phÃ¡t triá»ƒn tri thá»©c
- **Bridge the gap giá»¯a Query vÃ  KG**: User khÃ´ng biáº¿t entity Ä‘Æ°á»£c lÆ°u chÃ­nh xÃ¡c nhÆ° tháº¿ nÃ o trong KG
- **TÄƒng recall**: Nhiá»u entities Ä‘Æ°á»£c match hÆ¡n â†’ nhiá»u facts Ä‘Æ°á»£c retrieve hÆ¡n
- **Robustness**: Há»‡ thá»‘ng Ã­t nháº¡y cáº£m vá»›i cÃ¡ch viáº¿t cá»§a user

#### ğŸ“Š Káº¿t quáº£ thá»±c táº¿
```
TrÆ°á»›c: 31/64 cÃ¢u cÃ³ 0 KG facts
Sau:   20/64 cÃ¢u cÃ³ 0 KG facts
â†’ Cáº£i thiá»‡n 35% sá»‘ cÃ¢u cÃ³ thá»ƒ retrieve KG facts
```

---

### Cáº£i Tiáº¿n 4: Hybrid Retrieval (Semantic + Graph)

#### ğŸ“‹ Flow
```
Query: "What university is UCF?"
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    â”‚                    â”‚
    â–¼                    â–¼                    â–¼
[Entity Extract]    [Embed Query]       [KG Lookup]
    â”‚                    â”‚                    â”‚
    â”‚                    â–¼                    â”‚
    â”‚               FAISS Search              â”‚
    â”‚                    â”‚                    â”‚
    â”‚                    â–¼                    â”‚
    â”‚            semantic_scores              â”‚
    â”‚               [0.8, 0.6, 0.5, ...]     â”‚
    â”‚                    â”‚                    â”‚
    â–¼                    â”‚                    â–¼
[Fuzzy Match]            â”‚            [Get related entities]
    â”‚                    â”‚                    â”‚
    â”‚                    â”‚                    â–¼
    â”‚                    â”‚            graph_scores (entity overlap)
    â”‚                    â”‚               [0.3, 0.7, 0.2, ...]
    â”‚                    â”‚                    â”‚
    â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                             â”‚
    â”‚                             â–¼
    â”‚                    HYBRID SCORE
    â”‚              Î± Ã— semantic + (1-Î±) Ã— graph
    â”‚                    (Î± = 0.6)
    â”‚                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         TOP-K CHUNKS
                                  â”‚
                                  â–¼
                         LLM GENERATION
```

#### ğŸ¯ Má»¥c Ä‘Ã­ch
Káº¿t há»£p 2 nguá»“n thÃ´ng tin:
1. **Semantic similarity**: Chunks cÃ³ nghÄ©a gáº§n vá»›i query
2. **Graph connectivity**: Chunks chá»©a entities liÃªn quan trong KG

#### ğŸ’¡ Ã nghÄ©a trong phÃ¡t triá»ƒn tri thá»©c
- **Semantic search** tá»‘t cho: paraphrase, synonyms, context understanding
- **Graph search** tá»‘t cho: entity relationships, factual connections
- **Hybrid** = Best of both worlds

**VÃ­ dá»¥:**
```
Query: "What treats migraines?"

Semantic search cÃ³ thá»ƒ tráº£ vá»:
  "Headaches can be very painful..." (semantic similar nhÆ°ng khÃ´ng answer)

Graph search biáº¿t:
  "migraine" â†treatsâ† "sumatriptan"
  â†’ Chunk chá»©a "sumatriptan" Ä‘Æ°á»£c boost score
```

---

## âš ï¸ CÃ¡c Pháº§n Tá»« SAT ChÆ°a Sá»­ Dá»¥ng ÄÆ°á»£c

### 1. Graph Transformer

#### Má»¥c Ä‘Ã­ch ban Ä‘áº§u
- Há»c **learnable node embeddings** tá»« cáº¥u trÃºc graph
- Thay tháº¿ Node2Vec (random walk, static) báº±ng attention-based learning
- Capture Ä‘Æ°á»£c **global graph structure** thay vÃ¬ chá»‰ local neighborhoods

#### Táº¡i sao chÆ°a dÃ¹ng Ä‘Æ°á»£c?
```
Váº¥n Ä‘á»: SEGMENTATION FAULT khi KG > 5000 entities

NguyÃªn nhÃ¢n ká»¹ thuáº­t:
- Attention matrix cÃ³ size O(E Ã— E) vá»›i E = sá»‘ edges
- KG hiá»‡n táº¡i: 8452 edges â†’ matrix ~71 triá»‡u pháº§n tá»­
- Má»—i pháº§n tá»­ lÃ  float32 (4 bytes) â†’ ~284 MB chá»‰ cho 1 attention head
- Multi-head (8 heads) Ã— Multi-layer (3 layers) â†’ ~6.8 GB
- VÆ°á»£t quÃ¡ memory available â†’ Crash
```

#### CÃ¡ch kháº¯c phá»¥c tiá»m nÄƒng
| Approach | MÃ´ táº£ | Äá»™ khÃ³ |
|----------|-------|--------|
| **Mini-batching** | Chia graph thÃ nh subgraphs, process tá»«ng batch | â­â­ |
| **Sparse Attention** | Chá»‰ tÃ­nh attention cho k-nearest neighbors | â­â­â­ |
| **Graph Sampling** | Random sample edges Ä‘á»ƒ giáº£m size | â­ |
| **Gradient Checkpointing** | Trade compute for memory | â­â­ |
| **Mixed Precision** | DÃ¹ng float16 thay float32 | â­ |

---

### 2. Text-Graph Aligner (CLIP-style)

#### Má»¥c Ä‘Ã­ch ban Ä‘áº§u
```
Ã tÆ°á»Ÿng: Táº¡o SHARED EMBEDDING SPACE cho cáº£ text vÃ  graph

Text: "Aspirin is a medication"  â†’  [text_emb]  â”€â”
                                                  â”‚
                                                  â–¼
                                          SHARED SPACE
                                                  â–²
                                                  â”‚
Graph: (aspirin, type_of, medication)  â†’  [graph_emb] â”€â”˜

â†’ Query báº±ng text, search trong graph space
â†’ Hoáº·c ngÆ°á»£c láº¡i: cÃ³ entity, tÃ¬m text mÃ´ táº£
```

#### Táº¡i sao chÆ°a dÃ¹ng Ä‘Æ°á»£c?
```
Váº¥n Ä‘á» 1: THIáº¾U LABELED DATA
- Cáº§n pairs (text, entity) Ä‘á»ƒ train contrastive loss
- Dataset hiá»‡n táº¡i khÃ´ng cÃ³ annotation nÃ y
- SAT paper dÃ¹ng FB15k-237 cÃ³ sáºµn text descriptions

Váº¥n Ä‘á» 2: COMPUTATIONAL COST
- Train CLIP-style model cáº§n nhiá»u negative samples
- Batch size lá»›n (512-4096) Ä‘á»ƒ contrastive loss hiá»‡u quáº£
- Cáº§n GPU vá»›i memory lá»›n

Váº¥n Ä‘á» 3: COLD START
- ChÆ°a cÃ³ pre-trained weights cho domain-specific data
- Train from scratch cáº§n nhiá»u data vÃ  time
```

#### CÃ¡ch kháº¯c phá»¥c tiá»m nÄƒng
| Approach | MÃ´ táº£ | Äá»™ khÃ³ |
|----------|-------|--------|
| **DÃ¹ng LLM generate descriptions** | GPT/Llama táº¡o text cho má»—i entity | â­â­ |
| **Transfer learning** | Fine-tune tá»« pre-trained CLIP | â­â­ |
| **Self-supervised** | DÃ¹ng entity names lÃ m text descriptions | â­ |
| **DÃ¹ng Sentence-BERT** | Embed cáº£ entity names vÃ  text, khÃ´ng cáº§n train | â­ |

---

## ğŸ“Š So SÃ¡nh Pipeline: Simple vs Enhanced

| BÆ°á»›c | Simple GraphRAG | Enhanced GraphRAG | Cáº£i tiáº¿n |
|------|-----------------|-------------------|----------|
| **1. Chunking** | Fixed-size | Sentence-boundary aware | KhÃ´ng cáº¯t ngang cÃ¢u |
| **2. Entity Extraction** | spaCy NER only | spaCy NER + Dependency Parsing | ThÃªm relations |
| **3. Graph Structure** | Co-occurrence edges | Typed triples (head, rel, tail) | Biáº¿t quan há»‡ cá»¥ thá»ƒ |
| **4. Entity Storage** | String dict | ID mapping (entity2id) | Faster lookup |
| **5. Embeddings** | Node2Vec (static) | ~~Graph Transformer~~ â†’ Node2Vec* | *Disabled |
| **6. Retrieval** | Semantic only | Hybrid (semantic + graph) | Multi-signal |
| **7. Entity Matching** | Exact match | Fuzzy matching | Robust hÆ¡n |
| **8. Text-Graph Bridge** | KhÃ´ng cÃ³ | ~~CLIP-style~~ â†’ KhÃ´ng cÃ³* | *ChÆ°a train |

---

### Tá»•ng Káº¿t: Nhá»¯ng GÃ¬ ÄÃ£ Thá»±c Sá»± Hoáº¡t Äá»™ng

âœ… **Äang dÃ¹ng vÃ  hoáº¡t Ä‘á»™ng:**
1. Entity/Relation ID Mapping
2. Explicit Relation Extraction  
3. Fuzzy Entity Matching
4. Hybrid Retrieval
5. Triple format vá»›i confidence scores

âŒ **ÄÃ£ implement nhÆ°ng disabled:**
1. Graph Transformer (segfault)
2. Text-Graph Aligner (chÆ°a train)

â†’ **Thá»±c táº¿**: Enhanced GraphRAG hiá»‡n táº¡i lÃ  **Simple GraphRAG + Better Entity Handling + Explicit Relations + Hybrid Search**, chÆ°a pháº£i full SAT architecture.

---

## ğŸ“Š Káº¿t Quáº£ Thá»±c Nghiá»‡m

### Dataset
- **Nguá»“n:** `data/medical_custom.json`
- **Sá»‘ cÃ¢u há»i:** 64

### Build KG Statistics
```
ğŸ“Š Build Complete!
   - Chunks: 173
   - Entities: 5088
   - Relations: 8 
   - Triples: 8452
```

### QA Evaluation Results

| Metric | Káº¿t quáº£ |
|--------|---------|
| **Strict Match** (GT substring in Answer) | 8/64 (12.5%) |
| **Fuzzy Match** (60% word overlap) | 43/64 (67.2%) |
| **"Not stated in text"** | 5/64 (7.8%) |

### PhÃ¢n tÃ­ch chi tiáº¿t

**CÃ¢u Ä‘Ãºng (fuzzy match):**
```
Q: What institutional type is UCF?
A: "a public research university"
GT: "UCF is a public research university."
â†’ âœ… ÄÃºng ná»™i dung, chá»‰ khÃ¡c format
```

**CÃ¢u sai (khÃ´ng tÃ¬m Ä‘Æ°á»£c context):**
```
Q: Why is the University of Essex called one of the 'original plate glass universities'?
A: "not stated in the text"
GT: "Because it is included among the group of universities..."
â†’ âŒ Context khÃ´ng chá»©a thÃ´ng tin nÃ y
```

---

## ğŸ”§ Cáº¥u HÃ¬nh ÄÃ£ Sá»­ Dá»¥ng

```python
# build_enhanced_kg_cache.py
rag = EnhancedGraphRAG(
    embedding_model_name="all-MiniLM-L6-v2",
    use_graph_transformer=False,  # Disabled do segfault
    graph_transformer_dim=128,
    graph_transformer_layers=3,
)

# run_enhanced_baseline.py
TOP_K = 10      # Sá»‘ chunks retrieved
ALPHA = 0.6     # 60% semantic, 40% graph
```

---

## ğŸ“ Files ÄÆ°á»£c Táº¡o

| File | MÃ´ táº£ |
|------|-------|
| `enhanced_graphrag.py` | Main module vá»›i táº¥t cáº£ components |
| `build_enhanced_kg_cache.py` | Script build KG cache |
| `run_enhanced_baseline.py` | Script cháº¡y QA evaluation |
| `enhanced_sat_data/` | Folder chá»©a KG cache |
| `enhanced_results.json` | Káº¿t quáº£ QA (64 cÃ¢u) |

### Cáº¥u trÃºc `enhanced_sat_data/`:
```
enhanced_sat_data/
â”œâ”€â”€ chunks.json          # List cÃ¡c text chunks
â”œâ”€â”€ embeddings.npy       # Chunk embeddings (173, 384)
â”œâ”€â”€ faiss.index          # FAISS index cho search
â”œâ”€â”€ kg.pkl               # NetworkX graph
â”œâ”€â”€ chunk_entities.pkl   # Entity mapping per chunk
â”œâ”€â”€ entity2id.pkl        # Entity â†’ ID (SAT-style)
â”œâ”€â”€ relation2id.pkl      # Relation â†’ ID (SAT-style)
â”œâ”€â”€ triples.json         # [(head, rel, tail, conf), ...]
â””â”€â”€ meta.json            # Metadata
```

---

## ğŸ¯ Káº¿t Luáº­n

### Nhá»¯ng gÃ¬ Ä‘Ã£ há»c tá»« SAT:
1. âœ… **Graph Transformer architecture** - Multi-head attention trÃªn graph
2. âœ… **Entity/Relation ID mapping** - SAT-style data format
3. âœ… **CLIP-style alignment concept** - Text-Graph bridge
4. âœ… **Triple with confidence** - Structured KG format

### Nhá»¯ng gÃ¬ Ä‘Ã£ cáº£i tiáº¿n riÃªng:
1. âœ… **Fuzzy entity matching** - Giáº£i quyáº¿t normalization issues
2. âœ… **Explicit relation extraction** - Dependency parsing
3. âœ… **Canonical relation mapping** - Standardize verbs â†’ relations

### Háº¡n cháº¿:

1. âŒ **Graph Transformer bá»‹ vÃ´ hiá»‡u hÃ³a do lá»—i bá»™ nhá»› (Segfault)**
   - **Váº¥n Ä‘á»**: Khi Knowledge Graph cÃ³ hÆ¡n ~5000 entities, Graph Transformer gáº·p lá»—i segmentation fault do tiÃªu thá»¥ bá»™ nhá»› quÃ¡ lá»›n khi tÃ­nh attention matrix trÃªn toÃ n bá»™ edges.
   - **NguyÃªn nhÃ¢n**: Thuáº­t toÃ¡n hiá»‡n táº¡i tÃ­nh attention O(EÂ²) vá»›i E lÃ  sá»‘ edges, khÃ´ng cÃ³ cÆ¡ cháº¿ batching hay sparse attention.
   - **Há»‡ quáº£**: Máº¥t Ä‘i kháº£ nÄƒng há»c **learnable node embeddings** tá»« cáº¥u trÃºc graph, pháº£i fallback vá» Node2Vec embeddings tÄ©nh nhÆ° Simple GraphRAG.

2. âŒ **ChÆ°a train Ä‘Æ°á»£c Text-Graph Aligner (CLIP-style)**
   - **Váº¥n Ä‘á»**: Module alignment giá»¯a text embeddings vÃ  graph embeddings chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n, chá»‰ sá»­ dá»¥ng pre-computed embeddings Ä‘á»™c láº­p.
   - **NguyÃªn nhÃ¢n**: Thiáº¿u dá»¯ liá»‡u training cÃ³ nhÃ£n (text-entity pairs), vÃ  cáº§n computational resources Ä‘Ã¡ng ká»ƒ Ä‘á»ƒ train contrastive loss.
   - **Há»‡ quáº£**: KhÃ´ng táº­n dá»¥ng Ä‘Æ°á»£c Æ°u Ä‘iá»ƒm lá»›n nháº¥t cá»§a SAT paper - kháº£ nÄƒng query báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn nhÆ°ng tÃ¬m kiáº¿m hiá»‡u quáº£ trÃªn graph space thÃ´ng qua shared embedding space.

3. âŒ **5/64 cÃ¢u há»i (7.8%) khÃ´ng tÃ¬m Ä‘Æ°á»£c context phÃ¹ há»£p**
   - **Váº¥n Ä‘á»**: Má»™t sá»‘ cÃ¢u há»i khÃ´ng retrieve Ä‘Æ°á»£c chunks chá»©a thÃ´ng tin cáº§n thiáº¿t Ä‘á»ƒ tráº£ lá»i.
   - **NguyÃªn nhÃ¢n gá»‘c**:
     - Chunking strategy hiá»‡n táº¡i (fixed-size) cÃ³ thá»ƒ cáº¯t ngang cÃ¡c Ä‘oáº¡n thÃ´ng tin liÃªn quan
     - Entity extraction bá» sÃ³t má»™t sá»‘ entities do NER model khÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c (Ä‘áº·c biá»‡t vá»›i tiáº¿ng Viá»‡t hoáº·c thuáº­t ngá»¯ chuyÃªn ngÃ nh)
     - Semantic similarity giá»¯a cÃ¢u há»i vÃ  answer chunks khÃ´ng Ä‘á»§ cao
   - **Há»‡ quáº£**: Giá»›i háº¡n recall tá»‘i Ä‘a cá»§a há»‡ thá»‘ng á»Ÿ má»©c ~92%

### HÆ°á»›ng phÃ¡t triá»ƒn:
- [x] Fix Graph Transformer cho large-scale KG (batching/sampling) âœ…
- [ ] Train Text-Graph Aligner vá»›i contrastive loss
- [ ] ThÃªm multi-hop reasoning
- [ ] Cáº£i thiá»‡n relation extraction vá»›i LLM 

---

## ğŸš€ Giai Äoáº¡n 2: Graph Transformer vá»›i FB15k-237N (03/02/2026)

### ğŸ“ Chi Tiáº¿t Giai Äoáº¡n 1: Nhá»¯ng GÃ¬ ÄÃ£ LÃ m

á» giai Ä‘oáº¡n 1, tÃ´i **tá»± xÃ¢y dá»±ng Knowledge Graph tá»« Ä‘áº§u** báº±ng cÃ¡c ká»¹ thuáº­t sau:

#### 1. Entity/Relation ID Mapping - TÃ´i ÄÃ£ LÃ m GÃ¬?

**BÆ°á»›c thá»±c hiá»‡n:**
- Äá»c vÄƒn báº£n thÃ´, dÃ¹ng spaCy Ä‘á»ƒ nháº­n diá»‡n cÃ¡c thá»±c thá»ƒ (ngÆ°á»i, Ä‘á»‹a Ä‘iá»ƒm, tá»• chá»©c...)
- Má»—i láº§n gáº·p má»™t thá»±c thá»ƒ má»›i, gÃ¡n cho nÃ³ má»™t sá»‘ ID tÄƒng dáº§n
- TÆ°Æ¡ng tá»± vá»›i cÃ¡c quan há»‡: má»—i Ä‘á»™ng tá»«/quan há»‡ má»›i cÅ©ng Ä‘Æ°á»£c gÃ¡n má»™t ID

**Má»¥c Ä‘Ã­ch:**
- Chuyá»ƒn tá»« lÆ°u trá»¯ báº±ng chuá»—i kÃ½ tá»± sang lÆ°u trá»¯ báº±ng sá»‘, giÃºp mÃ¡y tÃ­nh xá»­ lÃ½ nhanh hÆ¡n
- Chuáº©n hÃ³a dá»¯ liá»‡u: "UCF", "ucf", "University of Central Florida" náº¿u lÃ  cÃ¹ng má»™t thá»±c thá»ƒ sáº½ cÃ³ cÃ¹ng ID
- LÃ  bÆ°á»›c báº¯t buá»™c náº¿u muá»‘n dÃ¹ng máº¡ng neural sau nÃ y (neural network cáº§n sá»‘, khÃ´ng nháº­n chuá»—i)

**CÃ³ trong quÃ¡ trÃ¬nh build KG khÃ´ng?** âœ… CÃ“ - ÄÃ¢y lÃ  bÆ°á»›c tÃ´i tá»± lÃ m, lÆ°u vÃ o `entity2id.pkl` vÃ  `relation2id.pkl`

#### 2. Explicit Relation Extraction - TÃ´i ÄÃ£ LÃ m GÃ¬?

**BÆ°á»›c thá»±c hiá»‡n:**
- PhÃ¢n tÃ­ch cÃº phÃ¡p cÃ¢u (dependency parsing) Ä‘á»ƒ tÃ¬m chá»§ ngá»¯, Ä‘á»™ng tá»«, tÃ¢n ngá»¯
- Tá»« Ä‘Ã³ rÃºt ra bá»™ ba: (chá»§ thá»ƒ, quan há»‡, Ä‘á»‘i tÆ°á»£ng)
- VÃ­ dá»¥: "UCF lÃ  má»™t trÆ°á»ng Ä‘áº¡i há»c cÃ´ng láº­p" â†’ (UCF, lÃ _loáº¡i, trÆ°á»ng Ä‘áº¡i há»c cÃ´ng láº­p)

**Má»¥c Ä‘Ã­ch:**
- Biáº¿t Ä‘Æ°á»£c **quan há»‡ cá»¥ thá»ƒ** giá»¯a cÃ¡c thá»±c thá»ƒ, khÃ´ng chá»‰ biáº¿t "chÃºng liÃªn quan"
- PhÃ¢n biá»‡t Ä‘Æ°á»£c "A gÃ¢y ra B" vá»›i "A chá»¯a Ä‘Æ°á»£c B" - ráº¥t quan trá»ng cho suy luáº­n

**CÃ³ trong quÃ¡ trÃ¬nh build KG khÃ´ng?** âœ… CÃ“ - TÃ´i tá»± extract vÃ  lÆ°u vÃ o `triples.json`

#### 3. Hybrid Retrieval - TÃ´i ÄÃ£ LÃ m GÃ¬?

**BÆ°á»›c thá»±c hiá»‡n:**
- Káº¿t há»£p 2 cÃ¡ch tÃ¬m kiáº¿m: semantic (ngá»¯ nghÄ©a) + graph (Ä‘á»“ thá»‹)
- Semantic: tÃ¬m Ä‘oáº¡n vÄƒn cÃ³ nghÄ©a gáº§n vá»›i cÃ¢u há»i
- Graph: tÃ¬m Ä‘oáº¡n vÄƒn chá»©a nhiá»u thá»±c thá»ƒ liÃªn quan trong KG (**Ä‘áº¿m entity overlap**)
- CÃ´ng thá»©c: Ä‘iá»ƒm = Î± Ã— Ä‘iá»ƒm_semantic + (1-Î±) Ã— Ä‘iá»ƒm_graph

**Má»¥c Ä‘Ã­ch:**
- Semantic giá»i tÃ¬m tá»« Ä‘á»“ng nghÄ©a, paraphrase
- Graph giá»i tÃ¬m quan há»‡ logic, thÃ´ng tin liÃªn káº¿t
- Káº¿t há»£p cáº£ hai Ä‘á»ƒ tÃ¬m kiáº¿m toÃ n diá»‡n hÆ¡n

**CÃ³ trong quÃ¡ trÃ¬nh build KG khÃ´ng?** âŒ KHÃ”NG - ÄÃ¢y lÃ  bÆ°á»›c retrieval, dÃ¹ng sau khi Ä‘Ã£ cÃ³ KG

**âš ï¸ LÆ°u Ã½ quan trá»ng vá» Giai Ä‘oáº¡n 1:**
- KG Ä‘Æ°á»£c **Tá»° BUILD** tá»« vÄƒn báº£n thÃ´ báº±ng NLP
- Graph score = **entity overlap** (Ä‘áº¿m sá»‘ thá»±c thá»ƒ trÃ¹ng), KHÃ”NG pháº£i graph embedding
- **CÃ“ DÃ™NG KG** khi retrieve (Ä‘áº¿m entities trong chunks)

---

### ğŸ“ Chi Tiáº¿t Giai Äoáº¡n 2: Nhá»¯ng GÃ¬ KhÃ¡c Biá»‡t

#### Data Láº¥y Tá»« ÄÃ¢u?

```
âš ï¸ QUAN TRá»ŒNG: Giai Ä‘oáº¡n 2 KHÃ”NG tá»± build KG!

Dá»¯ liá»‡u láº¥y tá»«: FB15k-237N (dataset CÃ“ Sáº´N cá»§a SAT paper)
- 14,541 thá»±c thá»ƒ vá»›i mÃ´ táº£ vÄƒn báº£n Ä‘áº§y Ä‘á»§ (id2text.txt)
- 237 loáº¡i quan há»‡ Ä‘Ã£ Ä‘á»‹nh nghÄ©a sáºµn (rel2id.txt)  
- 87,282 bá»™ ba (triples) Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n sáºµn (train.txt)

TÃ´i KHÃ”NG extract entity, KHÃ”NG extract relation, KHÃ”NG build KG má»›i!
```

#### Graph Transformer LÃ m GÃ¬?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GRAPH TRANSFORMER - VAI TRÃ’ THá»°C Sá»°                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Äáº¦U VÃ€O:  KG cÃ³ sáºµn (14541 entities, 87282 triples)                        â”‚
â”‚            â†“                                                                â”‚
â”‚  Xá»¬ LÃ:    Há»c vector Ä‘áº·c trÆ°ng (embedding) cho má»—i thá»±c thá»ƒ                â”‚
â”‚            - NhÃ¬n vÃ o cáº¥u trÃºc Ä‘á»“ thá»‹: ai káº¿t ná»‘i vá»›i ai                    â”‚
â”‚            - DÃ¹ng attention Ä‘á»ƒ tá»•ng há»£p thÃ´ng tin tá»« cÃ¡c lÃ¡ng giá»ng         â”‚
â”‚            â†“                                                                â”‚
â”‚  Äáº¦U RA:   Node embeddings (14541, 128) - má»—i entity 1 vector 128 chiá»u     â”‚
â”‚                                                                             â”‚
â”‚  âš ï¸ KHÃ”NG LÃ€M:                                                              â”‚
â”‚     âŒ KhÃ´ng Ä‘á»c vÄƒn báº£n                                                    â”‚
â”‚     âŒ KhÃ´ng nháº­n diá»‡n thá»±c thá»ƒ                                             â”‚
â”‚     âŒ KhÃ´ng rÃºt trÃ­ch quan há»‡                                              â”‚
â”‚     âŒ KhÃ´ng xÃ¢y dá»±ng KG má»›i                                                â”‚
â”‚                                                                             â”‚
â”‚  â†’ Graph Transformer CHá»ˆ Há»ŒC EMBEDDING tá»« KG Ä‘Ã£ cÃ³ sáºµn!                     â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### âš ï¸ Váº¥n Äá» ALPHA = 1.0: CÃ³ DÃ¹ng KG KhÃ´ng?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              THá»°C Táº¾: ALPHA = 1.0 â†’ KHÃ”NG DÃ™NG GRAPH!                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  CÃ´ng thá»©c: Ä‘iá»ƒm = Î± Ã— semantic + (1-Î±) Ã— graph                             â”‚
â”‚                                                                             â”‚
â”‚  Khi Î± = 1.0:  Ä‘iá»ƒm = 1.0 Ã— semantic + 0 Ã— graph = CHá»ˆ semantic             â”‚
â”‚                                                                             â”‚
â”‚  â†’ Káº¾T QUáº¢ 95.3% THá»°C CHáº¤T LÃ€ RAG THUáº¦N TÃšY!                               â”‚
â”‚  â†’ KHÃ”NG dÃ¹ng Graph Transformer embeddings                                  â”‚
â”‚  â†’ KHÃ”NG dÃ¹ng KG trong retrieval                                            â”‚
â”‚  â†’ Chá»‰ dÃ¹ng semantic search (FAISS + SentenceTransformer)                   â”‚
â”‚                                                                             â”‚
â”‚  Táº¡i sao váº«n Ä‘áº¡t 95.3%?                                                     â”‚
â”‚  - FB15k-237N cÃ³ id2text.txt vá»›i mÃ´ táº£ vÄƒn báº£n Ä‘áº§y Ä‘á»§ cho má»—i entity        â”‚
â”‚  - Semantic search trÃªn 14541 mÃ´ táº£ nÃ y tÃ¬m Ä‘Æ°á»£c context chÃ­nh xÃ¡c          â”‚
â”‚  - LLM vá»›i prompt cáº£i tiáº¿n suy luáº­n tá»‘t tá»« context                          â”‚
â”‚                                                                             â”‚
â”‚  âš ï¸ Graph Transformer embeddings ÄÃƒ TÃNH xong, chá»‰ KHÃ”NG ÄÆ¯á»¢C DÃ™NG         â”‚
â”‚     vÃ¬ khi thá»­ Î± < 1.0, káº¿t quáº£ tá»‡ hÆ¡n (45.3% vá»›i Î±=0.6)                    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### So SÃ¡nh 2 Giai Äoáº¡n (Báº£n RÃµ RÃ ng)

| Aspect | Giai Ä‘oáº¡n 1 (Enhanced GraphRAG) | Giai Ä‘oáº¡n 2 (Graph Transformer QA) |
|--------|--------------------------------|-----------------------------------|
| **Nguá»“n KG** | **Tá»± build** tá»« raw text | **CÃ³ sáºµn** (FB15k-237N) |
| **Entity Extraction** | âœ… CÃ³ (spaCy NER) | âŒ KhÃ´ng cáº§n |
| **Relation Extraction** | âœ… CÃ³ (Dependency Parsing) | âŒ KhÃ´ng cáº§n |
| **ID Mapping** | âœ… Tá»± táº¡o | âœ… CÃ³ sáºµn trong dataset |
| **Graph score lÃ  gÃ¬?** | **Entity overlap** (Ä‘áº¿m trÃ¹ng) | **Graph Transformer** embeddings |
| **CÃ³ dÃ¹ng KG khi retrieve?** | âœ… CÃ“ (Ä‘áº¿m entity overlap) | âŒ KHÃ”NG (Î±=1.0, pure semantic) |
| **Thá»±c cháº¥t lÃ  gÃ¬?** | Hybrid RAG (semantic + graph) | **Pure RAG** (chá»‰ semantic) |
| **Káº¿t quáº£** | 67.2% | 95.3% |

---

### Táº¡i Sao KhÃ´ng DÃ¹ng Graph Embeddings (Î± < 1.0)?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Váº¤N Äá»€: 2 KHÃ”NG GIAN KHÃ”NG LIÃŠN Káº¾T                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Text Embeddings (SentenceTransformer):                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  - Há»c tá»«: ngá»¯ nghÄ©a cá»§a tá»«, cÃ¢u                                            â”‚
â”‚  - "government" gáº§n vá»›i "state", "administration"                           â”‚
â”‚  - Äo lÆ°á»ng: Ä‘á»™ giá»‘ng vá» nghÄ©a                                              â”‚
â”‚                                                                             â”‚
â”‚  Graph Embeddings (Graph Transformer):                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  - Há»c tá»«: cáº¥u trÃºc Ä‘á»“ thá»‹ (ai ná»‘i vá»›i ai)                                  â”‚
â”‚  - entity_0 gáº§n entity_123 vÃ¬ cÃ³ chung nhiá»u lÃ¡ng giá»ng                     â”‚
â”‚  - Äo lÆ°á»ng: Ä‘á»™ giá»‘ng vá» vá»‹ trÃ­ trong Ä‘á»“ thá»‹                                â”‚
â”‚                                                                             â”‚
â”‚  âŒ HAI KHÃ”NG GIAN NÃ€Y KHÃ”NG CÃ™NG Há»† QUY CHIáº¾U!                             â”‚
â”‚                                                                             â”‚
â”‚  Káº¿t quáº£ test:                                                              â”‚
â”‚  - Î± = 1.0 (chá»‰ semantic): 95.3% âœ…                                         â”‚
â”‚  - Î± = 0.6 (hybrid):       45.3% âŒ (tá»‡ hÆ¡n ráº¥t nhiá»u!)                     â”‚
â”‚                                                                             â”‚
â”‚  â†’ Káº¿t há»£p 2 embeddings chÆ°a aligned = lÃ m há»ng káº¿t quáº£                     â”‚
â”‚  â†’ Cáº§n TRAIN TEXT-GRAPH ALIGNMENT má»›i dÃ¹ng Ä‘Æ°á»£c hybrid                      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### FB15k-237N Dataset - KG CÃ³ Sáºµn Cá»§a SAT

```
FB15k-237N/
â”œâ”€â”€ id2text.txt      # 14,541 entity descriptions (tá»« Wikipedia)
â”œâ”€â”€ mid2id.txt       # Freebase MID â†’ Entity ID mapping
â”œâ”€â”€ rel2id.txt       # 237 relation types
â”œâ”€â”€ train.txt        # 87,282 triples (head, relation, tail)
â”œâ”€â”€ valid.txt        # 7,041 triples
â””â”€â”€ test.txt         # 8,226 triples
```

**VÃ­ dá»¥ dá»¯ liá»‡u:**
```
# id2text.txt - Entity descriptions
0    A government is the system or group of people governing...
1    The University of Central Florida (UCF) is a public research university...
5    Tottenham Hotspur Football Club, commonly referred to as...

# train.txt - Triples (Ä‘Ã£ cÃ³ sáºµn quan há»‡)
/m/0146hc    /education/educational_institution/colors    /m/067z2v
/m/0146hc    /education/educational_institution/school_type    /m/05jxkf
```

### Graph Transformer - Vai TrÃ² Thá»±c Sá»±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              GRAPH TRANSFORMER KHÃ”NG Tá»° BUILD KG!                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Graph Transformer CHá»ˆ lÃ m 1 viá»‡c:                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚                                                                             â”‚
â”‚  INPUT:  KG Ä‘Ã£ cÃ³ sáºµn (entities, relations, triples)                        â”‚
â”‚          â†“                                                                  â”‚
â”‚  PROCESS: Há»c EMBEDDINGS tá»« cáº¥u trÃºc graph                                  â”‚
â”‚           - Multi-head attention trÃªn edges                                 â”‚
â”‚           - Aggregate thÃ´ng tin tá»« neighbors                                â”‚
â”‚           â†“                                                                 â”‚
â”‚  OUTPUT: Node embeddings (14541, 128) - má»—i entity 1 vector                 â”‚
â”‚                                                                             â”‚
â”‚  âš ï¸ KHÃ”NG LÃ€M:                                                              â”‚
â”‚     - KhÃ´ng extract entities tá»« text                                        â”‚
â”‚     - KhÃ´ng extract relations tá»« text                                       â”‚
â”‚     - KhÃ´ng build KG má»›i                                                    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Táº¡i Sao Hybrid Search Tháº¥t Báº¡i?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Váº¤N Äá»€: 2 EMBEDDING SPACES KHÃ”NG ALIGNED                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Text Embeddings (SentenceTransformer):                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  "government" â†’ [0.2, 0.5, 0.1, ...] (384-dim)                              â”‚
â”‚  Há»c tá»«: Ngá»¯ nghÄ©a cá»§a tá»«, synonyms, context                                â”‚
â”‚  "government" â‰ˆ "state", "administration", "regime"                         â”‚
â”‚                                                                             â”‚
â”‚  Graph Embeddings (Graph Transformer):                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  entity_0 â†’ [0.8, -0.3, 0.4, ...] (128-dim)                                 â”‚
â”‚  Há»c tá»«: Vá»‹ trÃ­ trong graph, neighbors, edge patterns                       â”‚
â”‚  entity_0 gáº§n entity_123 vÃ¬ cÃ³ chung nhiá»u neighbors                        â”‚
â”‚                                                                             â”‚
â”‚  âŒ 2 khÃ´ng gian nÃ y KHÃ”NG CÃ™NG Há»† QUY CHIáº¾U!                               â”‚
â”‚                                                                             â”‚
â”‚  Káº¿t quáº£ test:                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                              â”‚
â”‚  Î±=1.0 (semantic only):  95.3% accuracy  âœ…                                 â”‚
â”‚  Î±=0.6 (hybrid):         45.3% accuracy  âŒ                                 â”‚
â”‚                                                                             â”‚
â”‚  â†’ Graph embeddings lÃ m GIáº¢M hiá»‡u quáº£ khi chÆ°a aligned!                     â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Graph Transformer V2 - Giáº£i Quyáº¿t Segfault

**Váº¥n Ä‘á» cÅ©:**
```python
# V1: TÃ­nh attention cho Táº¤T Cáº¢ edges cÃ¹ng lÃºc
attention = softmax(Q @ K.T)  # O(EÂ²) memory â†’ SEGFAULT
```

**Giáº£i phÃ¡p V2:**
```python
# V2: Batched edge processing
for batch_edges in chunks(all_edges, batch_size=10000):
    attention_batch = compute_attention(batch_edges)
    aggregate(attention_batch)
```

**Káº¿t quáº£:**
- V1: Segfault vá»›i 5000+ entities
- V2: Cháº¡y Ä‘Æ°á»£c 14,541 entities trong **0.27 giÃ¢y**

### Cáº£i Thiá»‡n Prompt - Giáº£m "Not Stated"

**Prompt cÅ©:**
```
Answer using ONLY the provided context.
If the context does not contain the answer, reply: "not stated in the text"
```
â†’ LLM quÃ¡ nghiÃªm kháº¯c, tá»« chá»‘i tráº£ lá»i cÃ¢u há»i "WHY"

**Prompt má»›i:**
```
For "WHY/HOW" questions: Use reasoning to infer from context clues.
Even if not explicitly stated, derive logical conclusions.
ONLY say "Not stated" if there is absolutely NO relevant information.
Think step by step, then provide answer.
```
â†’ LLM Ä‘Æ°á»£c khuyáº¿n khÃ­ch SUY LUáº¬N

**Káº¿t quáº£:**
| Metric | Prompt CÅ© | Prompt Má»›i |
|--------|----------|------------|
| Not stated | 7/64 | **1/64** |
| Accuracy | 84.4% | **95.3%** |

### Káº¿t Quáº£ Cuá»‘i CÃ¹ng

| Há»‡ thá»‘ng | KG Type | Accuracy | Not Stated |
|----------|---------|----------|------------|
| Enhanced GraphRAG | Tá»± build (5088 entities) | 67.2% | 1/64 |
| **Graph Transformer QA** | FB15k-237N (14541 entities) | **95.3%** | 1/64 |

### Files Má»›i ÄÆ°á»£c Táº¡o

| File | MÃ´ táº£ |
|------|-------|
| `graph_transformer_v2.py` | Graph Transformer optimized vá»›i batched edge processing |
| `run_qa_with_graph_transformer.py` | QA pipeline vá»›i FB15k-237N |
| `test_graph_transformer_sat.py` | Test script cho Graph Transformer |
| `sat_kg_data/` | Cache cho embeddings vÃ  graph data |
| `qa_results_graph_transformer.json` | Káº¿t quáº£ QA (64 cÃ¢u) |

### HÆ°á»›ng Äi Tiáº¿p Theo

Äá»ƒ sá»­ dá»¥ng Graph Embeddings hiá»‡u quáº£, cáº§n **train Text-Graph Alignment**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TEXT-GRAPH ALIGNMENT (CLIP-style)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Text: "government"  â†’  [Text Encoder]  â†’  text_emb  â”€â”                     â”‚
â”‚                              â†“                        â”‚                     â”‚
â”‚                        Projection Head                â”‚                     â”‚
â”‚                              â†“                        â†“                     â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                        â”‚      SHARED SPACE            â”‚                     â”‚
â”‚                        â”‚   (Contrastive Loss)         â”‚                     â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                              â†‘                        â†‘                     â”‚
â”‚                        Projection Head                â”‚                     â”‚
â”‚                              â†‘                        â”‚                     â”‚
â”‚  Graph: entity_0  â†’  [Graph Transformer]  â†’  graph_emb â”€â”˜                   â”‚
â”‚                                                                             â”‚
â”‚  Training data: (entity_id, entity_text) pairs tá»« id2text.txt              â”‚
â”‚  Loss: InfoNCE Contrastive Loss                                            â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CÃ¡c bÆ°á»›c cáº§n lÃ m:**
- [ ] Táº¡o ProjectionHead module (MLP: 384 â†’ 256 vÃ  128 â†’ 256)
- [ ] Implement InfoNCE Contrastive Loss
- [ ] Training loop vá»›i FB15k-237N id2text pairs
- [ ] Evaluate hybrid retrieval sau khi align

---

*BÃ¡o cÃ¡o cáº­p nháº­t: 03/02/2026*
